# S3 Bucket Setup Guide

**Generated by:** claude-3.5-sonnet  
**Timestamp:** 2025-11-12T17:00:00Z  
**Version:** 1.0.0  
**Policy Version:** v1.0.0  
**Traceability:** REQ-1.3, REQ-4.2, REQ-6.4 → DESIGN-001 → TASK-1.2  
**Review Status:** Pending  
**Risk Level:** Level 2

## Overview

This guide explains how to set up the S3 bucket structure and upload CloudOps templates for the RDS Operations Dashboard.

## Prerequisites

1. **AWS CDK Deployment**: The S3 bucket must be created first via CDK deployment
2. **AWS CLI**: Installed and configured with appropriate credentials
3. **IAM Permissions**: Your AWS credentials must have S3 read/write permissions

### Required IAM Permissions

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:GetBucketVersioning",
        "s3:GetBucketEncryption",
        "s3:GetBucketLifecycleConfiguration",
        "s3:GetPublicAccessBlock"
      ],
      "Resource": [
        "arn:aws:s3:::rds-dashboard-data-*",
        "arn:aws:s3:::rds-dashboard-data-*/*"
      ]
    }
  ]
}
```

## Step 1: Deploy Infrastructure

First, deploy the CDK stack to create the S3 bucket:

```bash
cd infrastructure
npm install
cdk deploy DataStack --context environment=prod
```

This will create the S3 bucket with:
- Versioning enabled
- SSE-S3 encryption
- Lifecycle policies configured
- Public access blocked

## Step 2: Initialize Folder Structure

After the bucket is created, run the setup script to initialize the folder structure and upload templates.

### Option A: Python Script (Linux/Mac/Windows)

```bash
cd scripts
python setup-s3-structure.py --bucket-name rds-dashboard-data-123456789012-prod
```

**Options:**
- `--bucket-name`: (Required) S3 bucket name
- `--region`: AWS region (default: ap-southeast-1)
- `--templates-dir`: Path to templates directory (default: ../s3-templates)
- `--skip-verification`: Skip bucket configuration verification

**Example with custom region:**
```bash
python setup-s3-structure.py \
  --bucket-name rds-dashboard-data-123456789012-prod \
  --region us-east-1
```

### Option B: PowerShell Script (Windows)

```powershell
cd scripts
.\setup-s3-structure.ps1 -BucketName "rds-dashboard-data-123456789012-prod"
```

**Parameters:**
- `-BucketName`: (Required) S3 bucket name
- `-Region`: AWS region (default: ap-southeast-1)
- `-TemplatesDir`: Path to templates directory (default: ..\s3-templates)
- `-SkipVerification`: Skip bucket configuration verification

**Example with custom region:**
```powershell
.\setup-s3-structure.ps1 `
  -BucketName "rds-dashboard-data-123456789012-prod" `
  -Region "us-east-1"
```

## Step 3: Verify Setup

After running the setup script, verify the folder structure:

```bash
aws s3 ls s3://rds-dashboard-data-123456789012-prod/ --recursive
```

Expected output:
```
2025-11-12 16:00:00          0 cloudops-requests/.keep
2025-11-12 16:00:00          0 compliance-reports/.keep
2025-11-12 16:00:00          0 cost-reports/.keep
2025-11-12 16:00:00          0 historical-metrics/.keep
2025-11-12 16:00:00       3456 templates/cloudops_maintenance_template.md
2025-11-12 16:00:00       4567 templates/cloudops_parameter_change_template.md
2025-11-12 16:00:00       3890 templates/cloudops_scaling_template.md
2025-11-12 16:00:00          0 templates/.keep
```

## Folder Structure

The setup script creates the following folder structure:

```
rds-dashboard-data-{account-id}-{environment}/
├── historical-metrics/        # CloudWatch metrics archive (7-day retention)
├── compliance-reports/        # Daily compliance reports (90-day → Glacier)
├── cost-reports/              # Daily cost analysis (90-day → Glacier)
├── cloudops-requests/         # Generated CloudOps requests (1-year retention)
└── templates/                 # CloudOps request templates (no expiration)
    ├── cloudops_scaling_template.md
    ├── cloudops_parameter_change_template.md
    └── cloudops_maintenance_template.md
```

## CloudOps Templates

Three templates are uploaded to the `templates/` folder:

### 1. Scaling Template
Used for instance class changes (vertical scaling).

**Variables:**
- `{{INSTANCE_ID}}`, `{{CURRENT_INSTANCE_CLASS}}`, `{{TARGET_INSTANCE_CLASS}}`
- `{{AVG_CPU}}`, `{{PEAK_CPU}}`, `{{AVG_CONNECTIONS}}`
- `{{CURRENT_COST}}`, `{{NEW_COST}}`, `{{COST_DELTA}}`

### 2. Parameter Change Template
Used for modifying RDS parameter groups.

**Variables:**
- `{{INSTANCE_ID}}`, `{{CURRENT_PARAMETER_GROUP}}`
- `{{PARAMETER_CHANGES_TABLE}}`, `{{REQUIRES_REBOOT}}`
- `{{ESTIMATED_DOWNTIME}}`, `{{RISK_LEVEL}}`

### 3. Maintenance Window Template
Used for changing maintenance and backup windows.

**Variables:**
- `{{INSTANCE_ID}}`, `{{CURRENT_MAINTENANCE_WINDOW}}`, `{{NEW_MAINTENANCE_WINDOW}}`
- `{{CURRENT_BACKUP_WINDOW}}`, `{{NEW_BACKUP_WINDOW}}`
- `{{PENDING_MAINTENANCE_ACTIONS}}`

## Lifecycle Policies

The bucket is configured with the following lifecycle policies:

| Folder | Retention | Action |
|--------|-----------|--------|
| `historical-metrics/` | 7 days | Delete |
| `compliance-reports/` | 90 days | Transition to Glacier |
| `cost-reports/` | 90 days | Transition to Glacier |
| `cloudops-requests/` | 1 year | Delete |
| `templates/` | Permanent | None |

## Troubleshooting

### Error: Bucket not found

**Cause:** The S3 bucket hasn't been created yet or the name is incorrect.

**Solution:**
1. Verify the bucket name matches the CDK output
2. Ensure the CDK stack was deployed successfully
3. Check you're using the correct AWS account

### Error: Access Denied

**Cause:** Your AWS credentials don't have sufficient permissions.

**Solution:**
1. Verify your AWS credentials are configured: `aws sts get-caller-identity`
2. Ensure your IAM user/role has the required S3 permissions
3. Check the bucket policy doesn't restrict access

### Error: Template files not found

**Cause:** The templates directory path is incorrect.

**Solution:**
1. Verify you're running the script from the `scripts/` directory
2. Check the templates exist in `../s3-templates/`
3. Use the `--templates-dir` parameter to specify the correct path

### Warning: Versioning not enabled

**Cause:** The bucket was created without versioning.

**Solution:**
Enable versioning manually:
```bash
aws s3api put-bucket-versioning \
  --bucket rds-dashboard-data-123456789012-prod \
  --versioning-configuration Status=Enabled
```

### Warning: Lifecycle rules not configured

**Cause:** The CDK stack didn't apply lifecycle rules correctly.

**Solution:**
Redeploy the CDK stack:
```bash
cd infrastructure
cdk deploy DataStack --context environment=prod
```

## Manual Setup (Alternative)

If you prefer to set up manually without the scripts:

### 1. Create folders

```bash
BUCKET_NAME="rds-dashboard-data-123456789012-prod"

# Create folder markers
echo "" | aws s3 cp - s3://$BUCKET_NAME/historical-metrics/.keep
echo "" | aws s3 cp - s3://$BUCKET_NAME/compliance-reports/.keep
echo "" | aws s3 cp - s3://$BUCKET_NAME/cost-reports/.keep
echo "" | aws s3 cp - s3://$BUCKET_NAME/cloudops-requests/.keep
echo "" | aws s3 cp - s3://$BUCKET_NAME/templates/.keep
```

### 2. Upload templates

```bash
cd s3-templates

aws s3 cp cloudops_scaling_template.md \
  s3://$BUCKET_NAME/templates/ \
  --content-type text/markdown \
  --server-side-encryption AES256

aws s3 cp cloudops_parameter_change_template.md \
  s3://$BUCKET_NAME/templates/ \
  --content-type text/markdown \
  --server-side-encryption AES256

aws s3 cp cloudops_maintenance_template.md \
  s3://$BUCKET_NAME/templates/ \
  --content-type text/markdown \
  --server-side-encryption AES256
```

## Next Steps

After completing the S3 setup:

1. **Deploy Lambda Functions**: Deploy the discovery, health monitor, and other Lambda functions
2. **Configure EventBridge**: Set up scheduled rules for automated tasks
3. **Test Discovery**: Trigger a manual discovery run to populate the inventory
4. **Verify Data Flow**: Check that metrics are being written to S3

## Cost Estimation

Based on 50 RDS instances:

- **Storage**: ~5 GB/month = $0.12/month
- **Requests**: ~10,000 PUT/GET = $0.05/month
- **Data Transfer**: Minimal (same region) = $0.01/month
- **Glacier Storage**: ~2 GB after 90 days = $0.01/month
- **Total**: ~$0.19/month

## Security Considerations

- ✅ All objects encrypted with SSE-S3
- ✅ Public access blocked at bucket level
- ✅ SSL/TLS required for all requests
- ✅ Versioning enabled for data protection
- ✅ IAM role-based access only (no public access)
- ✅ CloudTrail logging enabled for audit trail

## Support

For issues or questions:
1. Check the troubleshooting section above
2. Review CloudWatch Logs for Lambda errors
3. Verify IAM permissions
4. Contact the DBA team lead

---

**Document Version:** 1.0.0  
**Last Updated:** 2025-11-12  
**Maintained By:** DBA Team
