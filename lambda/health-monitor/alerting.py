"""
Health Alerting and Threshold Evaluation

Generated by: claude-3.5-sonnet
Timestamp: 2025-11-12T20:00:00Z
Version: 1.0.0
Policy Version: v1.0.0
Traceability: REQ-2.2, REQ-2.4, REQ-2.5 → DESIGN-001 → TASK-3.2
Review Status: Pending
Risk Level: Level 2

Purpose: Evaluate metrics against thresholds and generate alerts.
Implements alert escalation for consecutive violations and SNS notifications.

Design Decisions:
- Configurable thresholds per metric
- Alert severity levels (Critical, High, Medium, Low)
- Consecutive violation tracking for escalation
- SNS notifications for critical alerts only
- Alert deduplication to prevent spam
"""

import os
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from enum import Enum

import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from shared import AWSClients, StructuredLogger

logger = StructuredLogger('alerting')


class AlertSeverity(Enum):
    """Alert severity levels."""
    CRITICAL = 'Critical'
    HIGH = 'High'
    MEDIUM = 'Medium'
    LOW = 'Low'


class ThresholdRule:
    """Threshold rule definition."""
    
    def __init__(
        self,
        metric_name: str,
        threshold: float,
        comparison: str,  # 'gt', 'lt', 'gte', 'lte'
        severity: AlertSeverity,
        consecutive_violations: int = 1,
        description: str = ''
    ):
        self.metric_name = metric_name
        self.threshold = threshold
        self.comparison = comparison
        self.severity = severity
        self.consecutive_violations = consecutive_violations
        self.description = description
    
    def evaluate(self, value: float) -> bool:
        """
        Evaluate if value violates threshold.
        
        Args:
            value: Metric value to evaluate
        
        Returns:
            bool: True if threshold violated
        """
        if self.comparison == 'gt':
            return value > self.threshold
        elif self.comparison == 'lt':
            return value < self.threshold
        elif self.comparison == 'gte':
            return value >= self.threshold
        elif self.comparison == 'lte':
            return value <= self.threshold
        return False


# Default threshold rules
DEFAULT_THRESHOLDS = [
    # CPU Utilization
    ThresholdRule(
        metric_name='CPUUtilization',
        threshold=80.0,
        comparison='gt',
        severity=AlertSeverity.HIGH,
        consecutive_violations=2,
        description='CPU utilization above 80% for 10 minutes'
    ),
    ThresholdRule(
        metric_name='CPUUtilization',
        threshold=95.0,
        comparison='gt',
        severity=AlertSeverity.CRITICAL,
        consecutive_violations=1,
        description='CPU utilization above 95%'
    ),
    
    # Database Connections
    ThresholdRule(
        metric_name='DatabaseConnections',
        threshold=90.0,  # Percentage of max_connections
        comparison='gt',
        severity=AlertSeverity.HIGH,
        consecutive_violations=2,
        description='Database connections above 90% of maximum'
    ),
    
    # Free Storage Space
    ThresholdRule(
        metric_name='FreeStorageSpace',
        threshold=10.0,  # GB
        comparison='lt',
        severity=AlertSeverity.CRITICAL,
        consecutive_violations=1,
        description='Free storage space below 10 GB'
    ),
    ThresholdRule(
        metric_name='FreeStorageSpace',
        threshold=20.0,  # GB
        comparison='lt',
        severity=AlertSeverity.HIGH,
        consecutive_violations=2,
        description='Free storage space below 20 GB'
    ),
    
    # IOPS
    ThresholdRule(
        metric_name='ReadIOPS',
        threshold=10000.0,
        comparison='gt',
        severity=AlertSeverity.MEDIUM,
        consecutive_violations=3,
        description='Read IOPS above 10,000'
    ),
    ThresholdRule(
        metric_name='WriteIOPS',
        threshold=10000.0,
        comparison='gt',
        severity=AlertSeverity.MEDIUM,
        consecutive_violations=3,
        description='Write IOPS above 10,000'
    ),
    
    # Disk Queue Depth
    ThresholdRule(
        metric_name='DiskQueueDepth',
        threshold=10.0,
        comparison='gt',
        severity=AlertSeverity.HIGH,
        consecutive_violations=2,
        description='Disk queue depth above 10'
    ),
]


class AlertManager:
    """
    Manages alert evaluation, tracking, and notifications.
    
    Usage:
        alert_mgr = AlertManager(config)
        alerts = alert_mgr.evaluate_metrics(instance, metrics)
        alert_mgr.send_notifications(alerts)
    """
    
    def __init__(self, config: Any):
        """
        Initialize alert manager.
        
        Args:
            config: Application configuration
        """
        self.config = config
        self.thresholds = DEFAULT_THRESHOLDS
        
        # Get DynamoDB table for alerts
        dynamodb = AWSClients.get_dynamodb_resource()
        self.alerts_table = dynamodb.Table(config.dynamodb.health_alerts_table)
    
    def evaluate_metrics(
        self,
        instance: Dict[str, Any],
        metrics: Dict[str, float]
    ) -> List[Dict[str, Any]]:
        """
        Evaluate metrics against thresholds and generate alerts.
        
        Args:
            instance: RDS instance data
            metrics: Dictionary of metric_name -> value
        
        Returns:
            list: Generated alerts
        
        Requirements: REQ-2.2 (threshold evaluation), REQ-2.4 (alerting)
        """
        instance_id = instance['instance_id']
        alerts = []
        
        for rule in self.thresholds:
            if rule.metric_name not in metrics:
                continue
            
            value = metrics[rule.metric_name]
            
            # Check if threshold violated
            if rule.evaluate(value):
                # Check violation history for escalation
                violation_count = self._get_violation_count(
                    instance_id,
                    rule.metric_name
                )
                
                # Increment violation count
                violation_count += 1
                self._update_violation_count(
                    instance_id,
                    rule.metric_name,
                    violation_count
                )
                
                # Generate alert if consecutive violations met
                if violation_count >= rule.consecutive_violations:
                    alert = self._create_alert(
                        instance=instance,
                        rule=rule,
                        value=value,
                        violation_count=violation_count
                    )
                    alerts.append(alert)
                    
                    logger.info(f'Alert generated: {rule.metric_name}',
                               instance_id=instance_id,
                               severity=rule.severity.value,
                               value=value,
                               threshold=rule.threshold)
            else:
                # Clear violation count if threshold not violated
                self._clear_violation_count(instance_id, rule.metric_name)
        
        return alerts
    
    def _create_alert(
        self,
        instance: Dict[str, Any],
        rule: ThresholdRule,
        value: float,
        violation_count: int
    ) -> Dict[str, Any]:
        """
        Create alert object.
        
        Args:
            instance: RDS instance data
            rule: Threshold rule
            value: Current metric value
            violation_count: Number of consecutive violations
        
        Returns:
            dict: Alert data
        """
        alert_id = f"{instance['instance_id']}#{rule.metric_name}#{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
        
        return {
            'alert_id': alert_id,
            'instance_id': instance['instance_id'],
            'account_id': instance['account_id'],
            'region': instance['region'],
            'metric_name': rule.metric_name,
            'severity': rule.severity.value,
            'threshold': rule.threshold,
            'current_value': value,
            'comparison': rule.comparison,
            'description': rule.description,
            'violation_count': violation_count,
            'status': 'Active',
            'created_at': datetime.utcnow().isoformat() + 'Z',
            'updated_at': datetime.utcnow().isoformat() + 'Z'
        }
    
    def store_alerts(self, alerts: List[Dict[str, Any]]) -> int:
        """
        Store alerts in DynamoDB.
        
        Args:
            alerts: List of alerts to store
        
        Returns:
            int: Number of alerts stored
        
        Requirements: REQ-2.2 (alert storage)
        """
        if not alerts:
            return 0
        
        stored_count = 0
        
        try:
            with self.alerts_table.batch_writer() as batch:
                for alert in alerts:
                    batch.put_item(Item=alert)
                    stored_count += 1
            
            logger.info(f'Stored {stored_count} alerts in DynamoDB')
            
        except Exception as e:
            logger.error('Failed to store alerts',
                        error=str(e))
        
        return stored_count
    
    def send_notifications(self, alerts: List[Dict[str, Any]]) -> int:
        """
        Send SNS notifications for critical alerts.
        
        Args:
            alerts: List of alerts
        
        Returns:
            int: Number of notifications sent
        
        Requirements: REQ-2.5 (SNS notifications)
        """
        # Filter for critical alerts only
        critical_alerts = [
            alert for alert in alerts
            if alert['severity'] == AlertSeverity.CRITICAL.value
        ]
        
        if not critical_alerts:
            return 0
        
        notifications_sent = 0
        
        try:
            sns = AWSClients.get_sns_client()
            
            # Group alerts by instance for better notification format
            alerts_by_instance = {}
            for alert in critical_alerts:
                instance_id = alert['instance_id']
                if instance_id not in alerts_by_instance:
                    alerts_by_instance[instance_id] = []
                alerts_by_instance[instance_id].append(alert)
            
            # Send notification for each instance
            for instance_id, instance_alerts in alerts_by_instance.items():
                message = self._build_notification_message(
                    instance_id,
                    instance_alerts
                )
                
                sns.publish(
                    TopicArn=self.config.monitoring.sns_topic_arn,
                    Subject=f'CRITICAL: RDS Health Alert - {instance_id}',
                    Message=message
                )
                
                notifications_sent += 1
                logger.info(f'Sent notification for {instance_id}',
                           alert_count=len(instance_alerts))
            
        except Exception as e:
            logger.error('Failed to send notifications',
                        error=str(e))
        
        return notifications_sent
    
    def _build_notification_message(
        self,
        instance_id: str,
        alerts: List[Dict[str, Any]]
    ) -> str:
        """
        Build SNS notification message.
        
        Args:
            instance_id: RDS instance identifier
            alerts: List of alerts for this instance
        
        Returns:
            str: Formatted notification message
        """
        message = f"""
CRITICAL RDS Health Alert

Instance: {instance_id}
Account: {alerts[0]['account_id']}
Region: {alerts[0]['region']}
Time: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC

Critical Issues Detected:
"""
        
        for alert in alerts:
            message += f"""
- {alert['metric_name']}: {alert['current_value']:.2f} (Threshold: {alert['threshold']:.2f})
  Severity: {alert['severity']}
  Description: {alert['description']}
  Consecutive Violations: {alert['violation_count']}
"""
        
        message += """

Action Required:
1. Review instance metrics in CloudWatch
2. Check application logs for errors
3. Consider scaling or optimization
4. Contact DBA team if issue persists

Dashboard: [Link to dashboard will be added]
"""
        
        return message
    
    def _get_violation_count(
        self,
        instance_id: str,
        metric_name: str
    ) -> int:
        """
        Get current violation count for metric.
        
        Args:
            instance_id: RDS instance identifier
            metric_name: Metric name
        
        Returns:
            int: Current violation count
        """
        # Implementation would query DynamoDB for violation history
        # For now, return 0 (will be enhanced in production)
        return 0
    
    def _update_violation_count(
        self,
        instance_id: str,
        metric_name: str,
        count: int
    ) -> None:
        """
        Update violation count for metric.
        
        Args:
            instance_id: RDS instance identifier
            metric_name: Metric name
            count: New violation count
        """
        # Implementation would update DynamoDB
        # For now, just log
        logger.debug(f'Violation count updated',
                    instance_id=instance_id,
                    metric_name=metric_name,
                    count=count)
    
    def _clear_violation_count(
        self,
        instance_id: str,
        metric_name: str
    ) -> None:
        """
        Clear violation count for metric.
        
        Args:
            instance_id: RDS instance identifier
            metric_name: Metric name
        """
        logger.debug(f'Violation count cleared',
                    instance_id=instance_id,
                    metric_name=metric_name)
