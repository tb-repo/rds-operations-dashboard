#!/usr/bin/env python3
"""
Cost Analyzer Lambda Handler

Generated by: claude-3.5-sonnet
Timestamp: 2025-11-13T00:00:00Z
Version: 1.0.0
Policy Version: v1.0.0
Traceability: REQ-4.1, REQ-4.2, REQ-4.3, REQ-4.4, REQ-4.5 â†’ DESIGN-001 â†’ TASK-4
Review Status: Pending
Risk Level: Level 2

Purpose: Calculate and track RDS costs with optimization recommendations.
Analyzes utilization patterns and generates right-sizing recommendations.

Trigger: EventBridge scheduled rule (daily at 03:00 SGT)
"""

import json
import os
import sys
from datetime import datetime, timedelta
from decimal import Decimal
from typing import Dict, List, Any, Optional

# Add parent directory to path for shared modules
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from shared import StructuredLogger
from shared import AWSClients
from shared import Config

# Import cost analyzer modules
from pricing import RDSPricingCalculator
from utilization import UtilizationAnalyzer
from recommendations import RecommendationEngine
from reporting import CostReporter

logger = StructuredLogger("cost-analyzer")


def lambda_handler(event, context):
    """
    Main Lambda handler for cost analysis.
    
    Triggered daily at 03:00 SGT to analyze RDS costs and generate recommendations.
    
    Args:
        event: EventBridge scheduled event
        context: Lambda context
        
    Returns:
        dict: Execution summary with cost totals and recommendations count
    """
    logger.info("Starting cost analysis", extra={
        "event": event,
        "request_id": context.aws_request_id
    })
    
    try:
        config = Config.load()
        
        # Initialize components
        pricing_calculator = RDSPricingCalculator(config)
        utilization_analyzer = UtilizationAnalyzer(config)
        recommendation_engine = RecommendationEngine(config)
        cost_reporter = CostReporter(config)
        
        # Step 1: Get RDS inventory
        logger.info("Retrieving RDS inventory")
        instances = get_rds_inventory()
        logger.info(f"Found {len(instances)} RDS instances to analyze")
        
        if not instances:
            logger.warn("No RDS instances found in inventory")
            return {
                "statusCode": 200,
                "message": "No instances to analyze",
                "total_cost": 0,
                "instances_analyzed": 0
            }
        
        # Step 2: Calculate costs for each instance
        logger.info("Calculating costs for all instances")
        instance_costs = []
        total_monthly_cost = Decimal('0')
        
        for instance in instances:
            try:
                cost_data = pricing_calculator.calculate_instance_cost(instance)
                instance_costs.append(cost_data)
                total_monthly_cost += Decimal(str(cost_data['monthly_cost']))
                
                logger.debug(f"Calculated cost for {instance['instance_id']}: ${cost_data['monthly_cost']}")
            except Exception as e:
                logger.error(f"Failed to calculate cost for {instance['instance_id']}: {str(e)}")
                continue
        
        logger.info(f"Total monthly cost: ${float(total_monthly_cost):.2f}")
        
        # Step 3: Analyze utilization patterns
        logger.info("Analyzing utilization patterns")
        utilization_data = utilization_analyzer.analyze_all_instances(instances)
        
        # Step 4: Generate recommendations
        logger.info("Generating optimization recommendations")
        recommendations = recommendation_engine.generate_recommendations(
            instances,
            instance_costs,
            utilization_data
        )
        
        logger.info(f"Generated {len(recommendations)} recommendations")
        
        # Step 5: Aggregate costs
        logger.info("Aggregating costs by account, region, and engine")
        cost_aggregations = aggregate_costs(instance_costs)
        
        # Step 6: Store cost data in DynamoDB
        logger.info("Storing cost data in DynamoDB")
        store_cost_data(instance_costs, cost_aggregations, recommendations)
        
        # Step 7: Generate and save report to S3
        logger.info("Generating cost report")
        report = cost_reporter.generate_report(
            instance_costs,
            cost_aggregations,
            recommendations,
            total_monthly_cost
        )
        
        report_key = cost_reporter.save_report_to_s3(report)
        logger.info(f"Cost report saved to S3: {report_key}")
        
        # Step 8: Store daily cost snapshot for trend tracking
        logger.info("Storing daily cost snapshot")
        cost_reporter.store_cost_snapshot(
            total_monthly_cost,
            cost_aggregations,
            len(instance_costs)
        )
        
        # Step 9: Calculate cost trends
        logger.info("Calculating cost trends")
        cost_trends = cost_reporter.calculate_cost_trends()
        
        # Step 10: Generate and save monthly trend report
        logger.info("Generating monthly trend report")
        trend_report = cost_reporter.generate_monthly_trend_report()
        if trend_report:
            trend_report_key = cost_reporter.save_trend_report_to_s3(trend_report)
            logger.info(f"Trend report saved to S3: {trend_report_key}")
        
        # Step 11: Publish CloudWatch metrics
        logger.info("Publishing CloudWatch metrics")
        cost_reporter.publish_cost_metrics(total_monthly_cost, cost_aggregations)
        publish_cost_metrics(total_monthly_cost, cost_aggregations, recommendations)
        
        # Return summary
        result = {
            "statusCode": 200,
            "message": "Cost analysis completed successfully",
            "total_monthly_cost": float(total_monthly_cost),
            "instances_analyzed": len(instance_costs),
            "recommendations_count": len(recommendations),
            "report_s3_key": report_key,
            "trend_report_s3_key": trend_report_key if trend_report else None,
            "cost_trends": cost_trends,
            "cost_by_account": {k: float(v) for k, v in cost_aggregations['by_account'].items()},
            "cost_by_region": {k: float(v) for k, v in cost_aggregations['by_region'].items()}
        }
        
        logger.info("Cost analysis completed", extra=result)
        return result
        
    except Exception as e:
        logger.error(f"Cost analysis failed: {str(e)}", exc_info=True)
        raise


def get_rds_inventory() -> List[Dict[str, Any]]:
    """
    Retrieve all RDS instances from DynamoDB inventory table.
    
    Returns:
        list: List of RDS instance records
    """
    config = Config.load()
    dynamodb = AWSClients.get_dynamodb_client()
    table_name = config.get('dynamodb_tables', {}).get('rds_inventory', 'rds-inventory-prod')
    
    try:
        response = dynamodb.scan(
            TableName=table_name,
            FilterExpression='attribute_exists(instance_id) AND #status = :status',
            ExpressionAttributeNames={
                '#status': 'status'
            },
            ExpressionAttributeValues={
                ':status': {'S': 'available'}
            }
        )
        
        instances = []
        for item in response.get('Items', []):
            instances.append(deserialize_dynamodb_item(item))
        
        # Handle pagination
        while 'LastEvaluatedKey' in response:
            response = dynamodb.scan(
                TableName=table_name,
                FilterExpression='attribute_exists(instance_id) AND #status = :status',
                ExpressionAttributeNames={
                    '#status': 'status'
                },
                ExpressionAttributeValues={
                    ':status': {'S': 'available'}
                },
                ExclusiveStartKey=response['LastEvaluatedKey']
            )
            for item in response.get('Items', []):
                instances.append(deserialize_dynamodb_item(item))
        
        return instances
        
    except Exception as e:
        logger.error(f"Failed to retrieve RDS inventory: {str(e)}")
        raise


def aggregate_costs(instance_costs: List[Dict[str, Any]]) -> Dict[str, Dict[str, Decimal]]:
    """
    Aggregate costs by account, region, engine type, and instance family.
    
    Args:
        instance_costs: List of instance cost data
        
    Returns:
        dict: Aggregated costs by different dimensions
    """
    aggregations = {
        'by_account': {},
        'by_region': {},
        'by_engine': {},
        'by_instance_family': {}
    }
    
    for cost_data in instance_costs:
        monthly_cost = Decimal(str(cost_data['monthly_cost']))
        
        # By account
        account_id = cost_data['account_id']
        aggregations['by_account'][account_id] = aggregations['by_account'].get(account_id, Decimal('0')) + monthly_cost
        
        # By region
        region = cost_data['region']
        aggregations['by_region'][region] = aggregations['by_region'].get(region, Decimal('0')) + monthly_cost
        
        # By engine
        engine = cost_data['engine']
        aggregations['by_engine'][engine] = aggregations['by_engine'].get(engine, Decimal('0')) + monthly_cost
        
        # By instance family (e.g., db.r6g from db.r6g.xlarge)
        instance_class = cost_data['instance_class']
        family = '.'.join(instance_class.split('.')[:2]) if '.' in instance_class else instance_class
        aggregations['by_instance_family'][family] = aggregations['by_instance_family'].get(family, Decimal('0')) + monthly_cost
    
    return aggregations


def store_cost_data(
    instance_costs: List[Dict[str, Any]],
    cost_aggregations: Dict[str, Dict[str, Decimal]],
    recommendations: List[Dict[str, Any]]
) -> None:
    """
    Store cost data and recommendations in DynamoDB.
    
    Args:
        instance_costs: List of instance cost data
        cost_aggregations: Aggregated cost data
        recommendations: List of optimization recommendations
    """
    config = Config.load()
    dynamodb = AWSClients.get_dynamodb_client()
    
    # Store daily cost snapshot
    table_name = config.get('dynamodb_tables', {}).get('cost_snapshots', 'cost-snapshots-prod')
    timestamp = datetime.utcnow().isoformat()
    date_str = datetime.utcnow().strftime('%Y-%m-%d')
    
    try:
        # Store aggregated snapshot
        snapshot_item = {
            'snapshot_id': {'S': f"daily-{date_str}"},
            'timestamp': {'S': timestamp},
            'date': {'S': date_str},
            'total_instances': {'N': str(len(instance_costs))},
            'total_monthly_cost': {'N': str(sum(Decimal(str(c['monthly_cost'])) for c in instance_costs))},
            'cost_by_account': {'M': {k: {'N': str(v)} for k, v in cost_aggregations['by_account'].items()}},
            'cost_by_region': {'M': {k: {'N': str(v)} for k, v in cost_aggregations['by_region'].items()}},
            'cost_by_engine': {'M': {k: {'N': str(v)} for k, v in cost_aggregations['by_engine'].items()}},
            'recommendations_count': {'N': str(len(recommendations))}
        }
        
        dynamodb.put_item(
            TableName=table_name,
            Item=snapshot_item
        )
        
        logger.info(f"Stored cost snapshot for {date_str}")
        
    except dynamodb.exceptions.ResourceNotFoundException:
        logger.warn(f"Cost snapshots table not found: {table_name}. Skipping storage.")
    except Exception as e:
        logger.error(f"Failed to store cost data: {str(e)}")
        # Don't raise - this is not critical


def publish_cost_metrics(
    total_cost: Decimal,
    cost_aggregations: Dict[str, Dict[str, Decimal]],
    recommendations: List[Dict[str, Any]]
) -> None:
    """
    Publish cost metrics to CloudWatch.
    
    Args:
        total_cost: Total monthly cost
        cost_aggregations: Aggregated costs
        recommendations: List of recommendations
    """
    cloudwatch = AWSClients.get_cloudwatch_client()
    namespace = 'RDSDashboard/CostAnalyzer'
    timestamp = datetime.utcnow()
    
    metrics = [
        {
            'MetricName': 'TotalMonthlyCost',
            'Value': float(total_cost),
            'Unit': 'None',
            'Timestamp': timestamp
        },
        {
            'MetricName': 'RecommendationsGenerated',
            'Value': len(recommendations),
            'Unit': 'Count',
            'Timestamp': timestamp
        }
    ]
    
    # Add per-account metrics
    for account_id, cost in cost_aggregations['by_account'].items():
        metrics.append({
            'MetricName': 'MonthlyCostByAccount',
            'Value': float(cost),
            'Unit': 'None',
            'Timestamp': timestamp,
            'Dimensions': [{'Name': 'AccountId', 'Value': account_id}]
        })
    
    # Add per-region metrics
    for region, cost in cost_aggregations['by_region'].items():
        metrics.append({
            'MetricName': 'MonthlyCostByRegion',
            'Value': float(cost),
            'Unit': 'None',
            'Timestamp': timestamp,
            'Dimensions': [{'Name': 'Region', 'Value': region}]
        })
    
    try:
        # CloudWatch allows max 20 metrics per call
        for i in range(0, len(metrics), 20):
            batch = metrics[i:i+20]
            cloudwatch.put_metric_data(
                Namespace=namespace,
                MetricData=batch
            )
        
        logger.info(f"Published {len(metrics)} cost metrics to CloudWatch")
        
    except Exception as e:
        logger.error(f"Failed to publish CloudWatch metrics: {str(e)}")
        # Don't raise - metrics are not critical


def deserialize_dynamodb_item(item: Dict[str, Any]) -> Dict[str, Any]:
    """
    Deserialize DynamoDB item to Python dict.
    
    Args:
        item: DynamoDB item with type descriptors
        
    Returns:
        dict: Deserialized Python dict
    """
    result = {}
    for key, value in item.items():
        if 'S' in value:
            result[key] = value['S']
        elif 'N' in value:
            result[key] = float(value['N']) if '.' in value['N'] else int(value['N'])
        elif 'BOOL' in value:
            result[key] = value['BOOL']
        elif 'M' in value:
            result[key] = deserialize_dynamodb_item(value['M'])
        elif 'L' in value:
            result[key] = [deserialize_dynamodb_item({'item': v})['item'] for v in value['L']]
    return result
