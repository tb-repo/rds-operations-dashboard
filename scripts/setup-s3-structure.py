#!/usr/bin/env python3
"""
S3 Bucket Structure Setup Script

Generated by: claude-3.5-sonnet
Timestamp: 2025-11-12T17:00:00Z
Version: 1.0.0
Policy Version: v1.0.0
Traceability: REQ-1.3, REQ-4.2, REQ-6.4 → DESIGN-001 → TASK-1.2
Review Status: Pending
Risk Level: Level 2

Purpose: Initialize S3 bucket folder structure and upload CloudOps templates

Usage:
    python setup-s3-structure.py --bucket-name rds-dashboard-data-123456789012-prod
    python setup-s3-structure.py --bucket-name rds-dashboard-data-123456789012-prod --region ap-southeast-1
"""

import argparse
import boto3
import os
import sys
from pathlib import Path

def create_folder_structure(s3_client, bucket_name):
    """
    Create folder structure in S3 bucket by uploading placeholder files.
    
    S3 doesn't have true folders, but we create the structure by uploading
    empty objects with folder-like keys.
    
    Args:
        s3_client: Boto3 S3 client
        bucket_name: Name of the S3 bucket
    """
    folders = [
        'historical-metrics/',
        'compliance-reports/',
        'cost-reports/',
        'cloudops-requests/',
        'templates/',
    ]
    
    print(f"Creating folder structure in bucket: {bucket_name}")
    
    for folder in folders:
        try:
            # Create a .keep file to ensure folder exists
            s3_client.put_object(
                Bucket=bucket_name,
                Key=f"{folder}.keep",
                Body=b'',
                ServerSideEncryption='AES256'
            )
            print(f"  ✓ Created folder: {folder}")
        except Exception as e:
            print(f"  ✗ Failed to create folder {folder}: {str(e)}")
            return False
    
    return True

def upload_templates(s3_client, bucket_name, templates_dir):
    """
    Upload CloudOps request templates to S3.
    
    Args:
        s3_client: Boto3 S3 client
        bucket_name: Name of the S3 bucket
        templates_dir: Local directory containing template files
    """
    print(f"\nUploading templates from: {templates_dir}")
    
    # Convert to Path object and resolve to absolute path
    templates_base = Path(templates_dir).resolve()
    
    template_files = [
        'cloudops_scaling_template.md',
        'cloudops_parameter_change_template.md',
        'cloudops_maintenance_template.md',
    ]
    
    for template_file in template_files:
        # Validate filename doesn't contain path traversal sequences
        if '..' in template_file or '/' in template_file or '\\' in template_file:
            print(f"  ✗ Invalid template filename: {template_file}")
            return False
        
        # Construct path and resolve to absolute path
        template_path = (templates_base / template_file).resolve()
        
        # Security check: Ensure resolved path is within templates directory
        try:
            template_path.relative_to(templates_base)
        except ValueError:
            print(f"  ✗ Path traversal detected: {template_file}")
            return False
        
        if not template_path.exists():
            print(f"  ⚠ Template not found: {template_path}")
            continue
        
        try:
            with open(template_path, 'rb') as f:
                s3_client.put_object(
                    Bucket=bucket_name,
                    Key=f"templates/{template_file}",
                    Body=f.read(),
                    ContentType='text/markdown',
                    ServerSideEncryption='AES256',
                    Metadata={
                        'version': '1.0.0',
                        'generated-by': 'rds-operations-dashboard'
                    }
                )
            print(f"  ✓ Uploaded: {template_file}")
        except Exception as e:
            print(f"  ✗ Failed to upload {template_file}: {str(e)}")
            return False
    
    return True

def verify_bucket_configuration(s3_client, bucket_name):
    """
    Verify bucket has correct configuration (versioning, encryption, etc.)
    
    Args:
        s3_client: Boto3 S3 client
        bucket_name: Name of the S3 bucket
    """
    print(f"\nVerifying bucket configuration: {bucket_name}")
    
    try:
        # Check versioning
        versioning = s3_client.get_bucket_versioning(Bucket=bucket_name)
        if versioning.get('Status') == 'Enabled':
            print("  ✓ Versioning: Enabled")
        else:
            print("  ⚠ Versioning: Not enabled (should be enabled)")
        
        # Check encryption
        try:
            encryption = s3_client.get_bucket_encryption(Bucket=bucket_name)
            print("  ✓ Encryption: Enabled")
        except s3_client.exceptions.ServerSideEncryptionConfigurationNotFoundError:
            print("  ⚠ Encryption: Not configured (should be SSE-S3)")
        
        # Check lifecycle rules
        try:
            lifecycle = s3_client.get_bucket_lifecycle_configuration(Bucket=bucket_name)
            rules = lifecycle.get('Rules', [])
            print(f"  ✓ Lifecycle Rules: {len(rules)} configured")
            for rule in rules:
                print(f"    - {rule.get('ID')}: {rule.get('Status')}")
        except s3_client.exceptions.NoSuchLifecycleConfiguration:
            print("  ⚠ Lifecycle Rules: Not configured")
        
        # Check public access block
        public_access = s3_client.get_public_access_block(Bucket=bucket_name)
        config = public_access.get('PublicAccessBlockConfiguration', {})
        if all([
            config.get('BlockPublicAcls'),
            config.get('IgnorePublicAcls'),
            config.get('BlockPublicPolicy'),
            config.get('RestrictPublicBuckets')
        ]):
            print("  ✓ Public Access: Blocked (all)")
        else:
            print("  ⚠ Public Access: Not fully blocked")
        
        return True
        
    except Exception as e:
        print(f"  ✗ Failed to verify configuration: {str(e)}")
        return False

def main():
    parser = argparse.ArgumentParser(
        description='Initialize S3 bucket structure for RDS Operations Dashboard'
    )
    parser.add_argument(
        '--bucket-name',
        required=True,
        help='S3 bucket name (e.g., rds-dashboard-data-123456789012-prod)'
    )
    parser.add_argument(
        '--region',
        default='ap-southeast-1',
        help='AWS region (default: ap-southeast-1)'
    )
    parser.add_argument(
        '--templates-dir',
        default='../s3-templates',
        help='Directory containing CloudOps templates (default: ../s3-templates)'
    )
    parser.add_argument(
        '--skip-verification',
        action='store_true',
        help='Skip bucket configuration verification'
    )
    
    args = parser.parse_args()
    
    # Resolve templates directory path
    script_dir = Path(__file__).parent
    templates_dir = (script_dir / args.templates_dir).resolve()
    
    print("=" * 60)
    print("RDS Operations Dashboard - S3 Setup")
    print("=" * 60)
    print(f"Bucket: {args.bucket_name}")
    print(f"Region: {args.region}")
    print(f"Templates: {templates_dir}")
    print("=" * 60)
    
    # Initialize S3 client
    try:
        s3_client = boto3.client('s3', region_name=args.region)
        print("\n✓ Connected to AWS S3")
    except Exception as e:
        print(f"\n✗ Failed to connect to AWS: {str(e)}")
        sys.exit(1)
    
    # Verify bucket exists
    try:
        s3_client.head_bucket(Bucket=args.bucket_name)
        print(f"✓ Bucket exists: {args.bucket_name}")
    except Exception as e:
        print(f"✗ Bucket not found or not accessible: {str(e)}")
        print("\nPlease ensure:")
        print("  1. The bucket exists")
        print("  2. You have appropriate IAM permissions")
        print("  3. The bucket name is correct")
        sys.exit(1)
    
    # Verify bucket configuration
    if not args.skip_verification:
        if not verify_bucket_configuration(s3_client, args.bucket_name):
            print("\n⚠ Bucket configuration verification failed")
            print("Continuing with setup, but please review bucket settings")
    
    # Create folder structure
    if not create_folder_structure(s3_client, args.bucket_name):
        print("\n✗ Failed to create folder structure")
        sys.exit(1)
    
    # Upload templates
    if not upload_templates(s3_client, args.bucket_name, templates_dir):
        print("\n✗ Failed to upload templates")
        sys.exit(1)
    
    print("\n" + "=" * 60)
    print("✓ S3 bucket setup completed successfully!")
    print("=" * 60)
    print("\nNext steps:")
    print("  1. Deploy Lambda functions")
    print("  2. Configure EventBridge rules")
    print("  3. Test discovery and health monitoring")
    print("\nFolder structure created:")
    print("  - historical-metrics/")
    print("  - compliance-reports/")
    print("  - cost-reports/")
    print("  - cloudops-requests/")
    print("  - templates/ (with 3 CloudOps templates)")

if __name__ == '__main__':
    main()
